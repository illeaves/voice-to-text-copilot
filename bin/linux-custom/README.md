# Linux Custom Build Directory

ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«é…ç½®ã—ãŸãƒã‚¤ãƒŠãƒªã¯ã€ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® `bin/linux/` ã‚ˆã‚Šå„ªå…ˆçš„ã«ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

## ğŸ“ åŸºæœ¬æƒ…å ±

Linux ç‰ˆã¯ CPU ç‰ˆãŒåŒæ¢±ã•ã‚Œã¦ã„ã¾ã™ãŒã€GPU ã‚’ãŠæŒã¡ã®å ´åˆã¯ä»¥ä¸‹ã®æ–¹æ³•ã§ GPU ç‰ˆã‚’ãƒ“ãƒ«ãƒ‰ã§ãã¾ã™:

- **NVIDIA GPU**: CUDA ç‰ˆ
- **AMD GPU**: ROCm ç‰ˆ
- **æ±ç”¨ GPU**: Vulkan ç‰ˆ

## ğŸ”§ ãƒ“ãƒ«ãƒ‰æ–¹æ³•

### 1. CUDA ç‰ˆï¼ˆNVIDIA GPUï¼‰

**å¿…è¦ãªã‚‚ã®:**

- [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads)
- GCC/G++ ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©

**ãƒ“ãƒ«ãƒ‰æ‰‹é †:**

```bash
cd whisper.cpp
rm -rf build
mkdir build && cd build

# CUDAå¯¾å¿œã§ãƒ“ãƒ«ãƒ‰
cmake .. -DGGML_CUDA=ON -DCMAKE_BUILD_TYPE=Release
make -j

# ãƒ“ãƒ«ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
cp bin/whisper-cli ../../bin/linux-custom/
```

### 2. ROCm ç‰ˆï¼ˆAMD GPUï¼‰

**å¿…è¦ãªã‚‚ã®:**

- [ROCm](https://rocmdocs.amd.com/)
- GCC/G++ ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©

**ãƒ“ãƒ«ãƒ‰æ‰‹é †:**

```bash
cd whisper.cpp
rm -rf build
mkdir build && cd build

# ROCmå¯¾å¿œã§ãƒ“ãƒ«ãƒ‰
cmake .. -DGGML_HIPBLAS=ON -DCMAKE_BUILD_TYPE=Release
make -j

# ãƒ“ãƒ«ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
cp bin/whisper-cli ../../bin/linux-custom/
```

### 3. Vulkan ç‰ˆï¼ˆæ±ç”¨ GPUï¼‰

**å¿…è¦ãªã‚‚ã®:**

- Vulkan SDK
- GCC/G++ ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©

**ãƒ“ãƒ«ãƒ‰æ‰‹é †:**

```bash
cd whisper.cpp
rm -rf build
mkdir build && cd build

# Vulkanå¯¾å¿œã§ãƒ“ãƒ«ãƒ‰
cmake .. -DGGML_VULKAN=ON -DCMAKE_BUILD_TYPE=Release
make -j

# ãƒ“ãƒ«ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
cp bin/whisper-cli ../../bin/linux-custom/
```

### 4. CPU ç‰ˆã®å†ãƒ“ãƒ«ãƒ‰

```bash
cd whisper.cpp
rm -rf build
mkdir build && cd build

# CPUç‰ˆ
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j

# ãƒ“ãƒ«ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼
cp bin/whisper-cli ../../bin/linux-custom/
```

## ğŸ“¦ å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«

åŸºæœ¬çš„ã«ã¯ `whisper-cli` å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ã§ OK ã§ã™ã€‚
ãŸã ã—ã€CUDA/ROCm ç‰ˆã®å ´åˆã¯å¯¾å¿œã™ã‚‹ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒã‚·ã‚¹ãƒ†ãƒ ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```
bin/linux-custom/
â””â”€â”€ whisper-cli          # å®Ÿè¡Œãƒ•ã‚¡ã‚¤ãƒ«
```

## ğŸ¯ ä½¿ã„æ–¹

1. ä¸Šè¨˜ã®æ‰‹é †ã§ãƒ“ãƒ«ãƒ‰
2. `whisper-cli` ã‚’ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚³ãƒ”ãƒ¼
3. å®Ÿè¡Œæ¨©é™ã‚’ä»˜ä¸: `chmod +x bin/linux-custom/whisper-cli`
4. æ‹¡å¼µæ©Ÿèƒ½ã‚’å†èµ·å‹•ï¼ˆã¾ãŸã¯ VS Code ã‚’ãƒªãƒ­ãƒ¼ãƒ‰ï¼‰
5. ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒã‚¤ãƒŠãƒªãŒè‡ªå‹•çš„ã«å„ªå…ˆä½¿ç”¨ã•ã‚Œã¾ã™

## ğŸ” ç¢ºèªæ–¹æ³•

VS Code ã®ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆãƒ‘ãƒãƒ«ï¼ˆ`Voice to Text + Copilot Chat`ï¼‰ã§ã€ã©ã®ãƒã‚¤ãƒŠãƒªãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã§ãã¾ã™ã€‚

## âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

- **CUDA ç‰ˆ**: NVIDIA GPU ã§å¤§å¹…ãªé«˜é€ŸåŒ–ãŒæœŸå¾…ã§ãã¾ã™
- **ROCm ç‰ˆ**: AMD GPU ã§é«˜é€ŸåŒ–ãŒæœŸå¾…ã§ãã¾ã™
- **Vulkan ç‰ˆ**: å¹…åºƒã„ GPU ã§å‹•ä½œã—ã¾ã™ãŒã€CUDA/ROCm ã»ã©ã®é«˜é€ŸåŒ–ã¯æœŸå¾…ã§ãã¾ã›ã‚“
- **CPU ç‰ˆ**: GPU ã‚’ä½¿ç”¨ã—ã¾ã›ã‚“ãŒã€ã™ã¹ã¦ã®ç’°å¢ƒã§å‹•ä½œã—ã¾ã™

---

**æ³¨æ„**: ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å†…å®¹ï¼ˆã“ã® README ä»¥å¤–ï¼‰ã¯ Git ã§è¿½è·¡ã•ã‚Œã¾ã›ã‚“ã€‚

---

# Linux Custom Build Directory (English)

Binaries placed in this directory will be used with priority over the default `bin/linux/`.

## ğŸ“ Basic Information

The Linux version includes a CPU build, but if you have a GPU, you can build GPU-accelerated versions:

- **NVIDIA GPU**: CUDA version
- **AMD GPU**: ROCm version
- **Generic GPU**: Vulkan version

## ğŸ”§ Build Instructions

### 1. CUDA Version (NVIDIA GPU)

**Requirements:**

- [CUDA Toolkit](https://developer.nvidia.com/cuda-downloads)
- GCC/G++ compiler

**Build Steps:**

```bash
cd whisper.cpp
rm -rf build
mkdir build && cd build

# Build with CUDA support
cmake .. -DGGML_CUDA=ON -DCMAKE_BUILD_TYPE=Release
make -j

# Copy built file
cp bin/whisper-cli ../../bin/linux-custom/
```

### 2. ROCm Version (AMD GPU)

**Requirements:**

- [ROCm](https://rocmdocs.amd.com/)
- GCC/G++ compiler

**Build Steps:**

```bash
cd whisper.cpp
rm -rf build
mkdir build && cd build

# Build with ROCm support
cmake .. -DGGML_HIPBLAS=ON -DCMAKE_BUILD_TYPE=Release
make -j

# Copy built file
cp bin/whisper-cli ../../bin/linux-custom/
```

### 3. Vulkan Version (Generic GPU)

**Requirements:**

- Vulkan SDK
- GCC/G++ compiler

**Build Steps:**

```bash
cd whisper.cpp
rm -rf build
mkdir build && cd build

# Build with Vulkan support
cmake .. -DGGML_VULKAN=ON -DCMAKE_BUILD_TYPE=Release
make -j

# Copy built file
cp bin/whisper-cli ../../bin/linux-custom/
```

### 4. CPU Version Rebuild

```bash
cd whisper.cpp
rm -rf build
mkdir build && cd build

# CPU version
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j

# Copy built file
cp bin/whisper-cli ../../bin/linux-custom/
```

## ğŸ“¦ Required Files

Basically, only the `whisper-cli` executable is needed.
However, for CUDA/ROCm versions, corresponding runtime libraries must be installed on your system.

```
bin/linux-custom/
â””â”€â”€ whisper-cli          # Executable
```

## ğŸ¯ Usage

1. Build using the steps above
2. Copy `whisper-cli` to this directory
3. Grant execute permission: `chmod +x bin/linux-custom/whisper-cli`
4. Restart the extension (or reload VS Code)
5. Binaries in this directory will be automatically prioritized

## ğŸ” Verification

You can check which binary is being used in the VS Code Output panel (`Voice to Text + Copilot Chat`).

## âš¡ Performance

- **CUDA version**: Significant speedup with NVIDIA GPUs
- **ROCm version**: Speedup with AMD GPUs
- **Vulkan version**: Works with a wide range of GPUs, but not as fast as CUDA/ROCm
- **CPU version**: Doesn't use GPU, but works on all systems

---

**Note**: Contents of this directory (except this README) are not tracked by Git.
